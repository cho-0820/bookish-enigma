from fastapi import FastAPI, UploadFile, File, HTTPException, Body
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import os
import json
from datetime import datetime
import re

# OCR ê´€ë ¨ ì¶”ê°€ import
from PIL import Image, ImageEnhance, ImageFilter
import pytesseract
import io
import cv2
import numpy as np

# Tesseract ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ ì„¤ì • (Windows)
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

# ì„ì‹œ: Tesseract ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸
import shutil
TESSERACT_INSTALLED = True
print("âœ… Tesseract OCRì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

# OpenAI API import
import openai

# ë°ì´í„°ë² ì´ìŠ¤ import
from database import DatabaseManager

app = FastAPI(
    title="AI í•™ìƒ ê¸€ í‰ê°€ ì‹œìŠ¤í…œ",
    description="ì†ê¸€ì”¨ OCR, AI í”¼ë“œë°±, ë‹¨ê³„ë³„ í‰ê°€ë¥¼ ì œê³µí•˜ëŠ” êµìœ¡ìš© ì‹œìŠ¤í…œ",
    version="2.0"
)

# CORS ì„¤ì • ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ìš´ì˜ì‹œì—ëŠ” íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

UPLOAD_DIR = os.path.join(os.path.dirname(__file__), 'uploads')
os.makedirs(UPLOAD_DIR, exist_ok=True)

# ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
try:
    db = DatabaseManager()
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
except Exception as e:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    db = None

# ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì ë° í¬ê¸° ì œí•œ
ALLOWED_EXTENSIONS = ["jpg", "jpeg", "png", "bmp", "gif", "tiff", "tif", "webp"]
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

def preprocess_image_for_ocr(image):
    """OCRì„ ìœ„í•œ ê³ ê¸‰ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í•œê¸€ ì†ê¸€ì”¨ íŠ¹í™”)"""
    # PIL ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    img_array = np.array(image)
    
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    if len(img_array.shape) == 3:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray = img_array
    
    print(f"ğŸ“¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {gray.shape}")
    
    # 1. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±° (ë” ê°•í™”)
    denoised = cv2.GaussianBlur(gray, (3, 3), 0)
    
    # 2. ìƒ¤í”„ë‹ í•„í„° ì ìš© (ê¸€ì ìœ¤ê³½ ì„ ëª…í™”)
    kernel_sharpen = np.array([[-1,-1,-1],
                              [-1, 9,-1],
                              [-1,-1,-1]])
    sharpened = cv2.filter2D(denoised, -1, kernel_sharpen)
    
    # 3. ëŒ€ë¹„ í–¥ìƒ (CLAHE - ë” ê°•í•œ ì„¤ì •)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
    enhanced = clahe.apply(sharpened)
    
    # 4. ì ì‘í˜• ì´ì§„í™” (Otsu + Gaussian)
    # ë¨¼ì € Otsuë¡œ ì„ê³„ê°’ ì°¾ê¸°
    _, otsu_binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # ì ì‘í˜• ì„ê³„ê°’ë„ ì ìš©í•´ì„œ ë¹„êµ
    adaptive_binary = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                           cv2.THRESH_BINARY, 11, 2)
    
    # ë‘ ê²°ê³¼ë¥¼ ì¡°í•© (ë” ë‚˜ì€ ê²°ê³¼ ì„ íƒ)
    combined_binary = cv2.bitwise_and(otsu_binary, adaptive_binary)
    
    # 5. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ê¸€ì ê°œì„ 
    # ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
    kernel_noise = np.ones((2,2), np.uint8)
    cleaned = cv2.morphologyEx(combined_binary, cv2.MORPH_OPEN, kernel_noise)
    
    # ê¸€ì ë‘ê»˜ ë³´ì •
    kernel_close = np.ones((1,1), np.uint8)
    processed = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel_close)
    
    # 6. í…ìŠ¤íŠ¸ ì˜ì—­ í™•ëŒ€ (OCR ì„±ëŠ¥ í–¥ìƒ)
    # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì˜ì—­ì„ ì°¾ì•„ì„œ í™•ëŒ€
    contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if contours:
        # ê°€ì¥ í° í…ìŠ¤íŠ¸ ì˜ì—­ ì°¾ê¸°
        largest_contour = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(largest_contour)
        
        # ì—¬ë°± ì¶”ê°€
        margin = 20
        x = max(0, x - margin)
        y = max(0, y - margin)
        w = min(processed.shape[1] - x, w + 2*margin)
        h = min(processed.shape[0] - y, h + 2*margin)
        
        # í…ìŠ¤íŠ¸ ì˜ì—­ë§Œ ì¶”ì¶œ
        text_area = processed[y:y+h, x:x+w]
        
        # ì¶©ë¶„íˆ í° ì˜ì—­ì´ë©´ ì‚¬ìš©
        if w > 50 and h > 30:
            processed = text_area
            print(f"âœ‚ï¸ í…ìŠ¤íŠ¸ ì˜ì—­ ì¶”ì¶œ: {w}x{h}")
    
    print(f"ğŸ”§ ì „ì²˜ë¦¬ ì™„ë£Œ: {processed.shape}")
    
    # numpy ë°°ì—´ì„ ë‹¤ì‹œ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜
    return Image.fromarray(processed)

def create_multiple_preprocessed_images(image):
    """ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ ì—¬ëŸ¬ ë²„ì „ ìƒì„±"""
    images = []
    
    # PIL ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    img_array = np.array(image)
    
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    if len(img_array.shape) == 3:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray = img_array
    
    print(f"ğŸ¨ ë‹¤ì¤‘ ì „ì²˜ë¦¬ ì‹œì‘: {gray.shape}")
    
    # 1. ê¸°ë³¸ ì „ì²˜ë¦¬ (ìœ„ì˜ í•¨ìˆ˜ì™€ ë™ì¼)
    basic_processed = preprocess_image_for_ocr(image)
    images.append(("ê¸°ë³¸ì „ì²˜ë¦¬", basic_processed))
    
    # 2. ê³ ëŒ€ë¹„ ë²„ì „
    try:
        # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”
        equalized = cv2.equalizeHist(gray)
        # ê°•í•œ ì´ì§„í™”
        _, high_contrast = cv2.threshold(equalized, 127, 255, cv2.THRESH_BINARY)
        images.append(("ê³ ëŒ€ë¹„", Image.fromarray(high_contrast)))
    except:
        pass
    
    # 3. ë¶€ë“œëŸ¬ìš´ ë²„ì „ (ë…¸ì´ì¦ˆê°€ ë§ì€ ì´ë¯¸ì§€ìš©)
    try:
        # ê°•í•œ ë¸”ëŸ¬ í›„ ìƒ¤í”„ë‹
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        kernel = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])
        soft_sharp = cv2.filter2D(blurred, -1, kernel)
        _, soft_binary = cv2.threshold(soft_sharp, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        images.append(("ë¶€ë“œëŸ¬ìš´ì²˜ë¦¬", Image.fromarray(soft_binary)))
    except:
        pass
    
    # 4. ì¹¨ì‹-íŒ½ì°½ ë²„ì „ (ì–‡ì€ ê¸€ì”¨ìš©)
    try:
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        kernel = np.ones((2,2), np.uint8)
        eroded = cv2.erode(binary, kernel, iterations=1)
        dilated = cv2.dilate(eroded, kernel, iterations=1)
        images.append(("ì¹¨ì‹íŒ½ì°½", Image.fromarray(dilated)))
    except:
        pass
    
    print(f"ğŸ¨ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(images)}ê°œ ë²„ì „ ìƒì„±")
    return images

def clean_ocr_text(text):
    """OCR ê²°ê³¼ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ë° ì •ë¦¬ (í•œê¸€ ìš°ì„ , ì˜ì–´ ì˜¤ì¸ì‹ ê°•í™” ê°ì§€)"""
    if not text or not text.strip():
        return ""
    
    # 1. ê¸°ë³¸ ì •ë¦¬
    cleaned = text.strip()
    
    # 2. í•œê¸€ì´ ì˜ì–´ë¡œ ì˜ëª» ì¸ì‹ëœ íŒ¨í„´ ê°ì§€ (ê°•í™”ëœ ë²„ì „)
    suspicious_english_patterns = [
        r'^[a-zA-Z\s]{1,3}$',  # ë„ˆë¬´ ì§§ì€ ì˜ë¬¸
        r'^[oOsS][a-zA-Z\s]*$',  # 'o', 'S' ë“±ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´
        r'[a-zA-Z]{1,2}\s+[a-zA-Z]{1,2}\s+[a-zA-Z]{1,2}',  # ì§§ì€ ì˜ë‹¨ì–´ë“¤ì´ ì—°ì†ìœ¼ë¡œ
        r'^[a-zA-Z]{1,2}\s+[a-zA-Z]+\s+[a-zA-Z]{1,2}',  # íŒ¨í„´: "oS witty Ee"
        r'[oOsSa-zA-Z]+\s+[wW][a-zA-Z]+\s+[eE][a-zA-Z]*',  # "oS witty Ee" íŒ¨í„´
        r'^[a-zA-Z]+\s+[a-zA-Z]+\s+[a-zA-Z]+\s+[a-zA-Z]+\s+[a-zA-Z]+',  # 5ê°œ ì´ìƒ ì§§ì€ ì˜ë‹¨ì–´
        r'[oO][sS]\s+[a-zA-Z]+',  # "oS" ë˜ëŠ” "OS"ë¡œ ì‹œì‘í•˜ëŠ” íŒ¨í„´
        r'[eE][eE]\s+[oO][dD]',  # "Ee OD" íŒ¨í„´
        r'a[eE]\s+[a-zA-Z]+ee',  # "ae ataanee" íŒ¨í„´
    ]
    
    # í•œê¸€ì´ í¬í•¨ë˜ì§€ ì•Šê³  ìœ„ íŒ¨í„´ì— í•´ë‹¹í•˜ë©´ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê²°ê³¼
    korean_chars = sum(1 for c in cleaned if 'ê°€' <= c <= 'í£')
    if korean_chars == 0:
        for pattern in suspicious_english_patterns:
            if re.search(pattern, cleaned.strip(), re.IGNORECASE):
                print(f"ğŸ” ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì˜ì–´ íŒ¨í„´ ê°ì§€: '{cleaned}' -> íŒ¨í„´: {pattern}")
                return ""  # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì˜ì–´ íŒ¨í„´ì€ ì œê±°
        
        # ì¶”ê°€ ê²€ì¦: ì „ì²´ í…ìŠ¤íŠ¸ê°€ ì˜ë¯¸ì—†ëŠ” ì˜ì–´ ì¡°í•©ì¸ì§€ í™•ì¸
        words = cleaned.split()
        if len(words) >= 3:
            # 3ë‹¨ì–´ ì´ìƒì¸ë° ëª¨ë‘ 3ê¸€ì ì´í•˜ì˜ ì˜ë‹¨ì–´ë“¤ì´ë©´ ì˜ì‹¬
            short_words = [w for w in words if len(w) <= 3 and w.isalpha()]
            if len(short_words) >= len(words) * 0.7:  # 70% ì´ìƒì´ ì§§ì€ ì˜ë‹¨ì–´
                print(f"ğŸ” ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì§§ì€ ì˜ë‹¨ì–´ ì¡°í•© ê°ì§€: '{cleaned}'")
                return ""
        
        # ëŒ€ì†Œë¬¸ìê°€ ë¶ˆê·œì¹™í•˜ê²Œ í˜¼ì¬ëœ íŒ¨í„´ ê°ì§€
        if re.search(r'[a-z][A-Z][a-z].*[A-Z][a-z]', cleaned):
            print(f"ğŸ” ë¶ˆê·œì¹™í•œ ëŒ€ì†Œë¬¸ì íŒ¨í„´ ê°ì§€: '{cleaned}'")
            return ""
    
    # 3. ì˜ë¯¸ì—†ëŠ” ë‹¨ì¼ ë¬¸ìë‚˜ íŠ¹ìˆ˜ë¬¸ì ì œê±°
    meaningless_chars = ['~', '.', ',', '!', '@', '#', '$', '%', '^', '&', '*', 
                        '(', ')', '-', '=', '+', '[', ']', '{', '}', '|', 
                        '\\', ':', ';', '"', "'", '<', '>', '?', '/', 'Â¥', 'â‚©']
    
    # 4. ì¤„ë³„ë¡œ ì²˜ë¦¬
    lines = cleaned.split('\n')
    valid_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # í•œê¸€ ë¬¸ì ê°œìˆ˜ í™•ì¸
        line_korean_chars = sum(1 for c in line if 'ê°€' <= c <= 'í£')
        line_english_chars = sum(1 for c in line if c.isalpha() and c.isascii())
        line_total_chars = len(line.replace(' ', ''))
        
        # ë„ˆë¬´ ì§§ì€ ì¤„ í•„í„°ë§ (1-2ê¸€ìì´ê³  ì˜ë¯¸ì—†ëŠ” ë¬¸ìë“¤)
        if len(line) <= 2:
            # ë‹¨ì¼ íŠ¹ìˆ˜ë¬¸ìë‚˜ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° ì œê±°
            if all(c in meaningless_chars + '0123456789' for c in line):
                continue
            # ë‹¨ì¼ ì˜ë¬¸ìë‚˜ ì˜ë¯¸ì—†ëŠ” ì¡°í•© ì œê±°
            if len(line) == 1 and (line.isalpha() and line.islower()):
                continue
        
        # í•œê¸€ì´ ì—†ê³  ì˜ì–´ë§Œ ìˆëŠ” ê²½ìš° ë” ì—„ê²©í•˜ê²Œ ê²€ì‚¬
        if line_korean_chars == 0 and line_english_chars > 0:
            # 3ê¸€ì ë¯¸ë§Œì˜ ì˜ì–´ ë‹¨ì–´ë“¤ë§Œ ìˆìœ¼ë©´ ì œê±°
            english_words = re.findall(r'[a-zA-Z]+', line)
            if all(len(word) < 3 for word in english_words):
                continue
            # ëŒ€ì†Œë¬¸ìê°€ í˜¼ì¬ëœ ì´ìƒí•œ íŒ¨í„´ ì œê±°
            if re.search(r'[a-z][A-Z][a-z]|[A-Z][a-z][A-Z]', line):
                continue
            
            # ì¤„ ì „ì²´ê°€ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì˜ì–´ íŒ¨í„´ì¸ì§€ ì¬ê²€ì‚¬
            for pattern in suspicious_english_patterns:
                if re.search(pattern, line, re.IGNORECASE):
                    print(f"ğŸ” ì¤„ë³„ ì˜ì–´ ì˜¤ì¸ì‹ íŒ¨í„´ ê°ì§€: '{line}'")
                    line = ""  # í•´ë‹¹ ì¤„ ì œê±°
                    break
        
        # ë¹ˆ ì¤„ì´ ë˜ì—ˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
        if not line:
            continue
        
        # 5. ê¹¨ì§„ ê¸€ì íŒ¨í„´ ì œê±°
        special_chars = sum(1 for c in line if not c.isalnum() and not 'ê°€' <= c <= 'í£' and c != ' ')
        
        if line_total_chars > 0:
            special_ratio = special_chars / line_total_chars
            # íŠ¹ìˆ˜ë¬¸ìê°€ 50% ì´ìƒì´ë©´ ì˜ë¯¸ì—†ëŠ” í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼
            if special_ratio > 0.5:
                continue
        
        # 6. ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ì¤„ë§Œ ìœ ì§€
        korean_words = re.findall(r'[ê°€-í£]{2,}', line)
        english_words = re.findall(r'[a-zA-Z]{3,}', line)
        
        # í•œê¸€ì´ ìš°ì„ , ì˜ì–´ëŠ” ë” ê¸´ ë‹¨ì–´ë§Œ ì¸ì •
        if korean_words or (line_korean_chars >= 2) or english_words:
            # 7. íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
            cleaned_line = re.sub(r'[^\w\sê°€-í£]', ' ', line)  # íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ
            cleaned_line = re.sub(r'\s+', ' ', cleaned_line)   # ì—°ì† ê³µë°±ì„ í•˜ë‚˜ë¡œ
            cleaned_line = cleaned_line.strip()
            
            if cleaned_line and len(cleaned_line) >= 2:
                valid_lines.append(cleaned_line)
    
    result = '\n'.join(valid_lines)
    
    # 8. ìµœì¢… ê²€ì¦ (í•œê¸€ ìš°ì„ ) - ë” ì—„ê²©í•œ ì¡°ê±´
    if result:
        final_korean = sum(1 for c in result if 'ê°€' <= c <= 'í£')
        final_english = sum(1 for c in result if c.isalpha() and c.isascii())
        
        # í•œê¸€ì´ ìˆìœ¼ë©´ ìš°ì„  ì±„íƒ
        if final_korean >= 2:
            print(f"âœ… í•œê¸€ í…ìŠ¤íŠ¸ ì±„íƒ: '{result[:50]}...' (í•œê¸€ {final_korean}ì)")
            return result
        # í•œê¸€ì´ ì—†ì–´ë„ ì˜ë¯¸ìˆëŠ” ì˜ì–´ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ì±„íƒ (ë” ì—„ê²©í•œ ì¡°ê±´)
        elif final_english >= 6:  # ìµœì†Œ 6ê¸€ì ì´ìƒì˜ ì˜ì–´ (ë” ì—„ê²©)
            print(f"âš ï¸ ì˜ì–´ í…ìŠ¤íŠ¸ ì±„íƒ: '{result[:50]}...' (ì˜ì–´ {final_english}ì)")
            return result
        else:
            print(f"âŒ í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶€ì¡±ìœ¼ë¡œ ì œê±°: '{result}' (í•œê¸€ {final_korean}ì, ì˜ì–´ {final_english}ì)")
    
    return ""

def clean_korean_ocr_text(text):
    """í•œê¸€ OCR ê²°ê³¼ ì „ìš© í›„ì²˜ë¦¬ (í’ˆì§ˆ ê°œì„  íŠ¹í™”)"""
    if not text or not text.strip():
        return ""
    
    # 1. ê¸°ë³¸ ì •ë¦¬
    cleaned = text.strip()
    
    print(f"ğŸ”¤ ì›ë³¸ í…ìŠ¤íŠ¸: '{cleaned}'")
    
    # 2. ìˆ«ìì™€ í•œê¸€ í˜¼ì¬ ë¹„ìœ¨ ì²´í¬
    korean_chars = sum(1 for c in cleaned if 'ê°€' <= c <= 'í£')
    digit_chars = sum(1 for c in cleaned if c.isdigit())
    total_chars = len(cleaned.replace(' ', '').replace('\n', ''))
    
    if total_chars > 0:
        digit_ratio = digit_chars / total_chars
        korean_ratio = korean_chars / total_chars
        
        print(f"ğŸ“Š ë¬¸ì ë¶„ì„: í•œê¸€ {korean_chars}ì({korean_ratio:.1%}), ìˆ«ì {digit_chars}ì({digit_ratio:.1%})")
        
        # ìˆ«ìê°€ 30% ì´ìƒì´ë©´ í’ˆì§ˆì´ ë‚®ì€ ê²ƒìœ¼ë¡œ íŒë‹¨
        if digit_ratio > 0.3:
            print(f"âŒ ìˆ«ì ë¹„ìœ¨ ê³¼ë‹¤: {digit_ratio:.1%} > 30%")
            return ""
        
        # í•œê¸€ì´ 50% ë¯¸ë§Œì´ë©´ í’ˆì§ˆì´ ë‚®ì€ ê²ƒìœ¼ë¡œ íŒë‹¨
        if korean_ratio < 0.5:
            print(f"âŒ í•œê¸€ ë¹„ìœ¨ ë¶€ì¡±: {korean_ratio:.1%} < 50%")
            return ""
    
    # 3. ì˜ë¯¸ì—†ëŠ” í•œê¸€ íŒ¨í„´ ê°ì§€
    korean_text_only = re.sub(r'[^ê°€-í£\s]', '', cleaned)
    korean_words = korean_text_only.split()
    
    if korean_words:
        # í•œê¸€ ë‹¨ì–´ë“¤ì˜ ê¸¸ì´ ë¶„ì„
        word_lengths = [len(word) for word in korean_words if len(word) > 0]
        avg_word_length = sum(word_lengths) / len(word_lengths) if word_lengths else 0
        
        print(f"ğŸ“ í•œê¸€ ë‹¨ì–´ ë¶„ì„: {len(korean_words)}ê°œ ë‹¨ì–´, í‰ê·  ê¸¸ì´: {avg_word_length:.1f}ì")
        
        # ë„ˆë¬´ ì§§ì€ ë‹¨ì–´ë“¤ë§Œ ìˆìœ¼ë©´ í’ˆì§ˆ ì˜ì‹¬
        if avg_word_length < 1.5:
            print(f"âŒ ë‹¨ì–´ ê¸¸ì´ ë¶€ì¡±: í‰ê·  {avg_word_length:.1f}ì < 1.5ì")
            return ""
        
        # 1ê¸€ì ë‹¨ì–´ê°€ 80% ì´ìƒì´ë©´ í’ˆì§ˆ ì˜ì‹¬
        short_words = [w for w in korean_words if len(w) == 1]
        if len(korean_words) > 0 and len(short_words) / len(korean_words) > 0.8:
            print(f"âŒ 1ê¸€ì ë‹¨ì–´ ê³¼ë‹¤: {len(short_words)}/{len(korean_words)}ê°œ")
            return ""
    
    # 4. ì˜ë¯¸ì—†ëŠ” ì—°ì† ë¬¸ì íŒ¨í„´ ê°ì§€
    suspicious_korean_patterns = [
        r'[ã„±-ã…]{2,}',  # ììŒë§Œ ì—°ì†
        r'[ã…-ã…£]{2,}',  # ëª¨ìŒë§Œ ì—°ì†
        r'ê°™ì€ë¬¸ì{3,}',  # ê°™ì€ ë¬¸ì 3ë²ˆ ì´ìƒ ë°˜ë³µ (ì¼ë°˜ì  íŒ¨í„´)
    ]
    
    for pattern in suspicious_korean_patterns:
        if re.search(pattern, cleaned):
            print(f"âŒ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ í•œê¸€ íŒ¨í„´ ê°ì§€: {pattern}")
            return ""
    
    # 5. ì¤„ë³„ ì²˜ë¦¬ ë° ì •ë¦¬
    lines = cleaned.split('\n')
    valid_lines = []
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # ì¤„ë³„ í•œê¸€ ë¹„ìœ¨ í™•ì¸
        line_korean = sum(1 for c in line if 'ê°€' <= c <= 'í£')
        line_total = len(line.replace(' ', ''))
        
        if line_total > 0 and line_korean / line_total >= 0.6:  # 60% ì´ìƒ í•œê¸€
            # íŠ¹ìˆ˜ë¬¸ìì™€ ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
            cleaned_line = re.sub(r'[^\w\sê°€-í£]', ' ', line)
            cleaned_line = re.sub(r'\s+', ' ', cleaned_line)
            cleaned_line = cleaned_line.strip()
            
            if len(cleaned_line) >= 2:  # ìµœì†Œ 2ê¸€ì ì´ìƒ
                valid_lines.append(cleaned_line)
                print(f"âœ… ìœ íš¨í•œ ì¤„: '{cleaned_line}'")
    
    result = '\n'.join(valid_lines)
    
    # 6. ìµœì¢… ê²€ì¦
    if result:
        final_korean = sum(1 for c in result if 'ê°€' <= c <= 'í£')
        final_total = len(result.replace(' ', '').replace('\n', ''))
        
        if final_total > 0:
            final_korean_ratio = final_korean / final_total
            
            if final_korean_ratio >= 0.7 and final_korean >= 4:  # 70% ì´ìƒ í•œê¸€, ìµœì†Œ 4ê¸€ì
                print(f"âœ… í•œê¸€ í…ìŠ¤íŠ¸ í’ˆì§ˆ ì–‘í˜¸: '{result}' (í•œê¸€ {final_korean_ratio:.1%})")
                return result
            else:
                print(f"âŒ ìµœì¢… í’ˆì§ˆ ë¶€ì¡±: í•œê¸€ {final_korean_ratio:.1%}, {final_korean}ê¸€ì")
    
    return ""

def analyze_korean_text_quality(text):
    """í•œê¸€ í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„ ë° ì ìˆ˜ ì‚°ì •"""
    if not text:
        return 0, "í…ìŠ¤íŠ¸ ì—†ìŒ", {}
    
    korean_chars = sum(1 for c in text if 'ê°€' <= c <= 'í£')
    digit_chars = sum(1 for c in text if c.isdigit())
    english_chars = sum(1 for c in text if c.isalpha() and c.isascii())
    total_chars = len(text.replace(' ', '').replace('\n', ''))
    
    if total_chars == 0:
        return 0, "ë¹ˆ í…ìŠ¤íŠ¸", {}
    
    # ë¶„ì„ ì •ë³´
    analysis = {
        "korean_chars": korean_chars,
        "digit_chars": digit_chars,
        "english_chars": english_chars,
        "total_chars": total_chars,
        "korean_ratio": korean_chars / total_chars,
        "digit_ratio": digit_chars / total_chars,
    }
    
    # ì ìˆ˜ ê³„ì‚° (í•œê¸€ íŠ¹í™”)
    score = 0
    
    # 1. í•œê¸€ ë¹„ìœ¨ (ìµœëŒ€ 40ì )
    korean_ratio = korean_chars / total_chars
    score += korean_ratio * 40
    
    # 2. í•œê¸€ ì¡´ì¬ ë³´ë„ˆìŠ¤ (20ì )
    if korean_chars >= 4:
        score += 20
    
    # 3. í•œê¸€ ë‹¨ì–´ í’ˆì§ˆ (ìµœëŒ€ 20ì )
    korean_words = re.findall(r'[ê°€-í£]{2,}', text)
    if korean_words:
        word_score = min(len(korean_words) * 3, 15)  # ë‹¨ì–´ ê°œìˆ˜
        avg_length = sum(len(w) for w in korean_words) / len(korean_words)
        if avg_length >= 2:
            word_score += 5  # ë‹¨ì–´ ê¸¸ì´ ë³´ë„ˆìŠ¤
        score += word_score
    
    # 4. ìˆ«ì ë¹„ìœ¨ í˜ë„í‹°
    digit_ratio = digit_chars / total_chars
    if digit_ratio > 0.2:  # 20% ì´ìƒ ìˆ«ìë©´ í˜ë„í‹°
        score -= (digit_ratio - 0.2) * 100  # ê°•í•œ í˜ë„í‹°
    
    # 5. ì ì ˆí•œ ê¸¸ì´ (10ì )
    if 6 <= total_chars <= 100:
        score += 10
    
    # 6. ë¬¸ì¥ êµ¬ì¡° ë³´ë„ˆìŠ¤ (10ì )
    if korean_chars >= 6 and ' ' in text:  # ê³µë°±ì´ ìˆê³  ì¶©ë¶„í•œ ê¸¸ì´
        score += 10
    
    score = max(0, min(100, int(score)))
    
    # í’ˆì§ˆ ì„¤ëª…
    if score >= 80:
        quality_desc = "ë§¤ìš° ì¢‹ìŒ (í•œê¸€)"
    elif score >= 60:
        quality_desc = "ì¢‹ìŒ (í•œê¸€)"
    elif score >= 40:
        quality_desc = "ë³´í†µ (í•œê¸€)"
    elif score >= 20:
        quality_desc = "ë‚˜ì¨ (í•œê¸€)"
    else:
        quality_desc = "ë§¤ìš° ë‚˜ì¨ (í•œê¸€)"
    
    return score, quality_desc, analysis

def evaluate_ocr_quality(text):
    """OCR ê²°ê³¼ì˜ í’ˆì§ˆì„ í‰ê°€ (í•œê¸€ ìµœìš°ì„  í‰ê°€, ì˜ì–´ ì˜¤ì¸ì‹ ê°ì§€)"""
    if not text:
        return 0, "í…ìŠ¤íŠ¸ ì—†ìŒ"
    
    # í•œê¸€, ì˜ë¬¸, ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ ê³„ì‚°
    korean_count = sum(1 for c in text if 'ê°€' <= c <= 'í£')
    english_count = sum(1 for c in text if c.isalpha() and c.isascii())
    digit_count = sum(1 for c in text if c.isdigit())
    special_count = sum(1 for c in text if not c.isalnum() and not 'ê°€' <= c <= 'í£' and c != ' ')
    
    total_count = len(text.replace(' ', '').replace('\n', ''))
    
    if total_count == 0:
        return 0, "ë¹ˆ í…ìŠ¤íŠ¸"
    
    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100) - í•œê¸€ ìµœìš°ì„ 
    quality_score = 0
    
    # 1. í•œê¸€ ë¹„ìœ¨ (í•œê¸€ì´ ìˆìœ¼ë©´ ê°•ë ¥í•œ ë³´ë„ˆìŠ¤)
    korean_ratio = korean_count / total_count
    if korean_ratio > 0:
        quality_score += korean_ratio * 60  # í•œê¸€ ë¹„ìœ¨ì— ë”°ë¥¸ ê¸°ë³¸ ì ìˆ˜ (ì¦ê°€)
        quality_score += 25  # í•œê¸€ ì¡´ì¬ ë³´ë„ˆìŠ¤ (ì¦ê°€)
        
        # í•œê¸€ ë‹¨ì–´ ê°œìˆ˜ ë³´ë„ˆìŠ¤
        korean_words = len(re.findall(r'[ê°€-í£]{2,}', text))
        if korean_words > 0:
            quality_score += min(korean_words * 5, 20)  # í•œê¸€ ë‹¨ì–´ ë³´ë„ˆìŠ¤ ì¦ê°€
        
        print(f"âœ… í•œê¸€ ë°œê²¬: {korean_count}ì ({korean_ratio:.1%}), ë‹¨ì–´: {korean_words}ê°œ")
    
    # 2. ì˜ë¬¸ ë¹„ìœ¨ (í•œê¸€ì´ ì—†ì„ ë•Œë§Œ ì ìš©)
    if korean_count == 0:
        english_ratio = english_count / total_count
        quality_score += english_ratio * 30  # ì˜ì–´ë§Œ ìˆì„ ë•Œ ê¸°ë³¸ ì ìˆ˜ ê°ì†Œ
        
        # ì˜ì–´ ì˜¤ì¸ì‹ íŒ¨í„´ ê°ì§€ ë° í˜ë„í‹°
        words = text.split()
        if len(words) >= 3:
            # ì§§ì€ ì˜ë‹¨ì–´ë“¤ì´ ë§ìœ¼ë©´ í˜ë„í‹°
            short_words = [w for w in words if len(w) <= 3 and w.isalpha()]
            if len(short_words) >= len(words) * 0.6:  # 60% ì´ìƒì´ ì§§ì€ ì˜ë‹¨ì–´
                quality_score -= 40  # ê°•í•œ í˜ë„í‹°
                print(f"âš ï¸ ì˜ì–´ ì˜¤ì¸ì‹ ì˜ì‹¬: ì§§ì€ ì˜ë‹¨ì–´ {len(short_words)}/{len(words)}ê°œ")
        
        # íŠ¹ì • ì˜ì‹¬ìŠ¤ëŸ¬ìš´ íŒ¨í„´ ê°ì§€
        suspicious_patterns = [
            r'[oO][sS]\s+[a-zA-Z]+',  # "oS witty" íŒ¨í„´
            r'[eE][eE]\s+[oO][dD]',   # "Ee OD" íŒ¨í„´  
            r'a[eE]\s+[a-zA-Z]+ee',   # "ae ataanee" íŒ¨í„´
            r'[a-z][A-Z][a-z].*[A-Z][a-z]',  # ë¶ˆê·œì¹™í•œ ëŒ€ì†Œë¬¸ì
        ]
        
        for pattern in suspicious_patterns:
            if re.search(pattern, text, re.IGNORECASE):
                quality_score -= 50  # ë§¤ìš° ê°•í•œ í˜ë„í‹°
                print(f"âŒ ì˜ì–´ ì˜¤ì¸ì‹ íŒ¨í„´ ê°ì§€: {pattern}")
                break
        
        print(f"âš ï¸ ì˜ì–´ë§Œ ê°ì§€: {english_count}ì ({english_ratio:.1%})")
    
    # 3. ìˆ«ì ë¹„ìœ¨
    digit_ratio = digit_count / total_count
    quality_score += digit_ratio * 10
    
    # 4. íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
    special_ratio = special_count / total_count
    quality_score += (1 - special_ratio) * 15
    
    # 5. ì ì ˆí•œ ê¸¸ì´ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸¸ì§€ ì•ŠìŒ)
    if 3 <= total_count <= 500:
        quality_score += 15
    
    # 6. ìµœì¢… ë³´ì •
    # í•œê¸€ì´ ìˆìœ¼ë©´ ìµœì†Œ ì ìˆ˜ ë³´ì¥
    if korean_count >= 2:
        quality_score = max(quality_score, 50)  # í•œê¸€ì´ ìˆìœ¼ë©´ ìµœì†Œ 50ì 
    
    # í•œê¸€ì´ ì—†ê³  ì˜ì–´ë§Œ ìˆìœ¼ë©´ ì ìˆ˜ ì œí•œ
    elif korean_count == 0 and english_count > 0:
        quality_score = min(quality_score, 70)  # ì˜ì–´ë§Œ ìˆìœ¼ë©´ ìµœëŒ€ 70ì 
    
    # ì ìˆ˜ ë²”ìœ„ ì œí•œ
    quality_score = max(0, min(100, int(quality_score)))
    
    # í’ˆì§ˆ ì„¤ëª… (í•œê¸€ ìš°ì„  ê¸°ì¤€)
    if korean_count >= 2:
        if quality_score >= 85:
            quality_desc = "ë§¤ìš° ì¢‹ìŒ (í•œê¸€)"
        elif quality_score >= 70:
            quality_desc = "ì¢‹ìŒ (í•œê¸€)"
        elif quality_score >= 50:
            quality_desc = "ë³´í†µ (í•œê¸€)"
        else:
            quality_desc = "ë‚˜ì¨ (í•œê¸€)"
    else:
        if quality_score >= 70:
            quality_desc = "ì¢‹ìŒ (ì˜ì–´)"
        elif quality_score >= 50:
            quality_desc = "ë³´í†µ (ì˜ì–´)"
        elif quality_score >= 30:
            quality_desc = "ë‚˜ì¨ (ì˜ì–´)"
        else:
            quality_desc = "ë§¤ìš° ë‚˜ì¨ (ì˜ì–´)"
    
    print(f"ğŸ“Š í’ˆì§ˆ í‰ê°€: {quality_score}ì  ({quality_desc}) - í•œê¸€:{korean_count}ì, ì˜ì–´:{english_count}ì")
    
    return quality_score, quality_desc

def try_multiple_ocr_methods(image):
    """ì†ê¸€ì”¨ íŠ¹í™” í™•ì¥ OCR ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„"""
    results = []
    
    print("ğŸ” ì†ê¸€ì”¨ íŠ¹í™” OCR ì‹œì‘!")
    
    # 1. ì†ê¸€ì”¨ íŠ¹í™” ì´ë¯¸ì§€ ë³€í˜• ìƒì„±
    handwriting_variants = create_handwriting_variants(image)
    
    # 2. ê¸°ì¡´ ì¼ë°˜ ì „ì²˜ë¦¬ ì´ë¯¸ì§€ë“¤ë„ ìƒì„±
    general_variants = create_multiple_preprocessed_images(image)
    
    # ëª¨ë“  ì´ë¯¸ì§€ ë³€í˜•ë“¤ ê²°í•©
    all_variants = handwriting_variants + general_variants
    
    print(f"ğŸ¨ ì´ {len(all_variants)}ê°œ ì´ë¯¸ì§€ ë³€í˜• ìƒì„±")
    
    # ê° ì´ë¯¸ì§€ ë³€í˜•ì— ëŒ€í•´ ì†ê¸€ì”¨ íŠ¹í™” OCR ë°©ë²•ë“¤ ì‹œë„
    for variant_name, processed_image in all_variants:
        print(f"\nğŸ–¼ï¸ {variant_name} ì´ë¯¸ì§€ë¡œ OCR ì‹œë„...")
        
        # ì†ê¸€ì”¨ì— ìµœì í™”ëœ PSM ëª¨ë“œë“¤
        psm_modes = [
            (6, "ê· ë“±ë¶„í• "),    # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¸”ë¡ 
            (8, "ë‹¨ì–´ë‹¨ìœ„"),    # ë‹¨ì¼ ë‹¨ì–´ - ì†ê¸€ì”¨ì— ì¢‹ìŒ
            (7, "ë‹¨ì¼ë¼ì¸"),    # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¼ì¸
            (13, "ì›ì‹œë¼ì¸"),   # ì›ì‹œ ë¼ì¸, ì¡°ì • ì—†ìŒ - ì†ê¸€ì”¨ íŠ¹í™”
            (4, "ë‹¨ì¼ì»¬ëŸ¼"),    # ë‹¨ì¼ ì»¬ëŸ¼
        ]
        
        for psm, psm_desc in psm_modes:
            # í•œêµ­ì–´ ì „ìš© ì‹œë„
            try:
                print(f"  ğŸ“ í•œêµ­ì–´ì „ìš© PSM{psm}({psm_desc}) ì‹œë„...")
                
                # DPI ì„¤ì • ì¶”ê°€ (ê³ í•´ìƒë„)
                config = f'--psm {psm} --dpi 300'
                text = pytesseract.image_to_string(processed_image, lang='kor', config=config)
                
                cleaned_text = enhance_korean_ocr_result(text)
                if cleaned_text:
                    score, desc, analysis = analyze_korean_text_quality(cleaned_text)
                    
                    # ì†ê¸€ì”¨ íŠ¹í™” ë³´ë„ˆìŠ¤
                    if "ì†ê¸€ì”¨" in variant_name:
                        score += 25  # ì†ê¸€ì”¨ ì „ì²˜ë¦¬ ë³´ë„ˆìŠ¤
                    if psm in [8, 13]:  # ì†ê¸€ì”¨ì— ì¢‹ì€ PSM
                        score += 15
                    else:
                        score += 10
                    
                    if score > 100: score = 100
                    
                    method_name = f"í•œêµ­ì–´({variant_name}-PSM{psm})"
                    results.append((method_name, cleaned_text, score, desc, analysis))
                    print(f"    âœ… ì„±ê³µ: '{cleaned_text[:40]}...' (í’ˆì§ˆ: {score}ì )")
                else:
                    print(f"    âŒ í’ˆì§ˆ ë¶€ì¡±ìœ¼ë¡œ ì œê±°ë¨")
                    
            except Exception as e:
                print(f"    âŒ ì˜¤ë¥˜: {e}")
            
            # í•œì˜ í˜¼í•©ë„ ì‹œë„ (ë°±ì—…ìš©)
            if psm in [6, 7]:  # ì¼ë°˜ì ì¸ PSMë§Œ
                try:
                    print(f"  ğŸ”¤ í•œì˜í˜¼í•© PSM{psm} ì‹œë„...")
                    
                    config = f'--psm {psm} --dpi 300'
                    text = pytesseract.image_to_string(processed_image, lang='kor+eng', config=config)
                    
                    cleaned_text = enhance_korean_ocr_result(text)
                    if cleaned_text:
                        score, desc, analysis = analyze_korean_text_quality(cleaned_text)
                        
                        # í˜¼í•© ëª¨ë“œëŠ” ë³´ë„ˆìŠ¤ ì ê²Œ
                        if "ì†ê¸€ì”¨" in variant_name:
                            score += 15
                        score += 5
                        
                        if score > 100: score = 100
                        
                        method_name = f"í•œì˜í˜¼í•©({variant_name}-PSM{psm})"
                        results.append((method_name, cleaned_text, score, desc, analysis))
                        print(f"    âœ… ì„±ê³µ: '{cleaned_text[:40]}...' (í’ˆì§ˆ: {score}ì )")
                    else:
                        print(f"    âŒ í’ˆì§ˆ ë¶€ì¡±ìœ¼ë¡œ ì œê±°ë¨")
                        
                except Exception as e:
                    print(f"    âŒ ì˜¤ë¥˜: {e}")
    
    print(f"\nğŸ” OCR ì™„ë£Œ: {len(results)}ê°œ ë°©ë²•ì—ì„œ ìœ íš¨í•œ ê²°ê³¼ íšë“")
    
    # ê²°ê³¼ê°€ ìˆìœ¼ë©´ í’ˆì§ˆ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    if results:
        results.sort(key=lambda x: x[2], reverse=True)  # ì ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ
        print("\nğŸ† ìµœì¢… ê²°ê³¼ ìˆœìœ„:")
        for i, (method, text, score, desc, analysis) in enumerate(results[:10], 1):
            korean_ratio = analysis.get('korean_ratio', 0) * 100
            digit_ratio = analysis.get('digit_ratio', 0) * 100
            print(f"  {i}ìœ„. {method}")
            print(f"      ì ìˆ˜: {score}ì  ({desc})")
            print(f"      í…ìŠ¤íŠ¸: '{text[:50]}{'...' if len(text) > 50 else ''}'")
            print(f"      êµ¬ì„±: í•œê¸€ {korean_ratio:.0f}%, ìˆ«ì {digit_ratio:.0f}%")
            print()
    
    # ê¸°ì¡´ formatì— ë§ì¶° ë°˜í™˜ (í˜¸í™˜ì„±)
    converted_results = []
    for method, text, score, desc, analysis in results:
        converted_results.append((method, text, score, desc))
    
    return converted_results

def preprocess_for_handwriting(image):
    """ì†ê¸€ì”¨ íŠ¹í™” ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    img_array = np.array(image)
    
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
    if len(img_array.shape) == 3:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray = img_array
    
    print(f"âœï¸ ì†ê¸€ì”¨ ì „ì²˜ë¦¬ ì‹œì‘: {gray.shape}")
    
    # 1. í•´ìƒë„ ì¦ëŒ€ (2ë°° í™•ëŒ€)
    height, width = gray.shape
    enlarged = cv2.resize(gray, (width*2, height*2), interpolation=cv2.INTER_CUBIC)
    print(f"ğŸ” í•´ìƒë„ ì¦ëŒ€: {gray.shape} â†’ {enlarged.shape}")
    
    # 2. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    denoised = cv2.GaussianBlur(enlarged, (3, 3), 0)
    
    # 3. ì–¸ìƒ¤í”„ ë§ˆìŠ¤í‚¹ìœ¼ë¡œ ì„ ëª…í™” ê°•í™”
    gaussian = cv2.GaussianBlur(denoised, (0, 0), 2.0)
    unsharp_mask = cv2.addWeighted(denoised, 1.5, gaussian, -0.5, 0)
    
    # 4. ëŒ€ë¹„ í–¥ìƒ (CLAHE - ì†ê¸€ì”¨ íŠ¹í™” ì„¤ì •)
    clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(16,16))
    enhanced = clahe.apply(unsharp_mask)
    
    # 5. ì ì‘í˜• ì´ì§„í™” (ì†ê¸€ì”¨ìš© ì„¤ì •)
    # ì—¬ëŸ¬ ë°©ë²•ì„ ì‹œë„í•˜ì—¬ ìµœì  ê²°ê³¼ ì„ íƒ
    
    # ë°©ë²• 1: ì ì‘í˜• ê°€ìš°ì‹œì•ˆ
    adaptive_gaussian = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                             cv2.THRESH_BINARY, 21, 10)
    
    # ë°©ë²• 2: ì ì‘í˜• í‰ê· 
    adaptive_mean = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_MEAN_C, 
                                         cv2.THRESH_BINARY, 21, 10)
    
    # ë°©ë²• 3: Otsu
    _, otsu_binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # ì„¸ ë°©ë²• ì¤‘ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ ì„ íƒ (í° í”½ì…€ ë¹„ìœ¨ë¡œ íŒë‹¨)
    methods = [
        ("ì ì‘í˜•_ê°€ìš°ì‹œì•ˆ", adaptive_gaussian),
        ("ì ì‘í˜•_í‰ê· ", adaptive_mean), 
        ("Otsu", otsu_binary)
    ]
    
    best_method = None
    best_score = 0
    
    for name, binary_img in methods:
        white_ratio = np.sum(binary_img == 255) / binary_img.size
        # ì ì ˆí•œ í°ìƒ‰ ë¹„ìœ¨ (70-90%)ì¸ ê²ƒì„ ì„ í˜¸
        if 0.7 <= white_ratio <= 0.9:
            score = 100 - abs(white_ratio - 0.8) * 100  # 80%ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        else:
            score = max(0, 50 - abs(white_ratio - 0.8) * 100)
        
        print(f"  ğŸ“Š {name}: í°ìƒ‰ ë¹„ìœ¨ {white_ratio:.1%}, ì ìˆ˜ {score:.0f}")
        
        if score > best_score:
            best_score = score
            best_method = (name, binary_img)
    
    if best_method:
        method_name, binary = best_method
        print(f"  âœ… ì„ íƒëœ ì´ì§„í™”: {method_name}")
    else:
        binary = adaptive_gaussian
        print(f"  âš ï¸ ê¸°ë³¸ê°’ ì‚¬ìš©: ì ì‘í˜•_ê°€ìš°ì‹œì•ˆ")
    
    # 6. ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ì—°ê²°ëœ ê¸€ì ë¶„ë¦¬
    # ìˆ˜ì§ì„  ì œê±° (ì—°ê²°ëœ ê¸€ì ë¶„ë¦¬ìš©)
    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 3))
    temp = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel, iterations=1)
    
    # ì‘ì€ ë…¸ì´ì¦ˆ ì œê±°
    noise_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    cleaned = cv2.morphologyEx(temp, cv2.MORPH_OPEN, noise_kernel, iterations=1)
    
    # ê¸€ì ë‘ê»˜ ì•½ê°„ ì¦ê°€ (OCR ì¸ì‹ë¥  í–¥ìƒ)
    thick_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    thickened = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, thick_kernel, iterations=1)
    
    print(f"âœï¸ ì†ê¸€ì”¨ ì „ì²˜ë¦¬ ì™„ë£Œ")
    
    return Image.fromarray(thickened)

def create_handwriting_variants(image):
    """ì†ê¸€ì”¨ìš© ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ë³€í˜• ìƒì„±"""
    variants = []
    
    # ê¸°ë³¸ ì†ê¸€ì”¨ ì „ì²˜ë¦¬
    handwriting_processed = preprocess_for_handwriting(image)
    variants.append(("ì†ê¸€ì”¨_ê¸°ë³¸", handwriting_processed))
    
    # ì›ë³¸ ì´ë¯¸ì§€ë¡œë„ ì—¬ëŸ¬ ì²˜ë¦¬
    img_array = np.array(image)
    if len(img_array.shape) == 3:
        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    else:
        gray = img_array
    
    # 1. ê³ í•´ìƒë„ + ê°•í•œ ì„ ëª…í™”
    try:
        large = cv2.resize(gray, None, fx=3, fy=3, interpolation=cv2.INTER_CUBIC)
        kernel_sharp = np.array([[-1,-1,-1,-1,-1],
                                [-1, 2, 2, 2,-1],
                                [-1, 2, 8, 2,-1],
                                [-1, 2, 2, 2,-1],
                                [-1,-1,-1,-1,-1]]) / 8
        sharp = cv2.filter2D(large, -1, kernel_sharp)
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(sharp)
        _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        variants.append(("ê³ í•´ìƒë„_ì„ ëª…", Image.fromarray(binary)))
    except:
        pass
    
    # 2. ì—°ê²° ë¶„ë¦¬ íŠ¹í™”
    try:
        # ê°•í•œ ì¹¨ì‹ìœ¼ë¡œ ì—°ê²° ë¶„ë¦¬
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        erode_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))
        eroded = cv2.erode(binary, erode_kernel, iterations=2)
        dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        restored = cv2.dilate(eroded, dilate_kernel, iterations=1)
        variants.append(("ì—°ê²°ë¶„ë¦¬", Image.fromarray(restored)))
    except:
        pass
    
    # 3. íšŒì „ ë³´ì • (Â±2ë„)
    try:
        for angle in [-2, 2]:
            center = (gray.shape[1]//2, gray.shape[0]//2)
            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            rotated = cv2.warpAffine(gray, rotation_matrix, (gray.shape[1], gray.shape[0]), 
                                   borderMode=cv2.BORDER_REPLICATE)
            _, binary = cv2.threshold(rotated, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            variants.append((f"íšŒì „{angle}ë„", Image.fromarray(binary)))
    except:
        pass
    
    print(f"âœï¸ ì†ê¸€ì”¨ ë³€í˜• ì™„ë£Œ: {len(variants)}ê°œ ë²„ì „")
    return variants

def validate_file(file: UploadFile) -> tuple[bool, str]:
    """íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬"""
    if not file.filename:
        return False, "íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
    
    ext = file.filename.split('.')[-1].lower()
    if ext not in ALLOWED_EXTENSIONS:
        return False, f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ({', '.join(ALLOWED_EXTENSIONS)}ë§Œ ê°€ëŠ¥)"
    
    return True, ""

async def validate_file_size(file: UploadFile) -> tuple[bool, str]:
    """íŒŒì¼ í¬ê¸° ê²€ì‚¬"""
    contents = await file.read()
    if len(contents) > MAX_FILE_SIZE:
        return False, f"íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ({MAX_FILE_SIZE // (1024*1024)}MB ì´í•˜ë§Œ ê°€ëŠ¥)"
    
    # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë˜ëŒë¦¼
    await file.seek(0)
    return True, ""

@app.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """ë‹¨ìˆœ íŒŒì¼ ì—…ë¡œë“œ (OCR ì—†ìŒ)"""
    try:
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
        valid, error_msg = validate_file(file)
        if not valid:
            raise HTTPException(status_code=400, detail=error_msg)
        
        valid, error_msg = await validate_file_size(file)
        if not valid:
            raise HTTPException(status_code=400, detail=error_msg)
        
        contents = await file.read()
        
        # íŒŒì¼ ì €ì¥ (ì¤‘ë³µ ë°©ì§€)
        save_name = file.filename
        save_path = os.path.join(UPLOAD_DIR, save_name)
        count = 1
        while os.path.exists(save_path):
            name, ext = os.path.splitext(file.filename)
            save_name = f"{name}_{count}{ext}"
            save_path = os.path.join(UPLOAD_DIR, save_name)
            count += 1
        
        with open(save_path, "wb") as f:
            f.write(contents)
        
        return JSONResponse(content={
            "filename": save_name, 
            "message": "íŒŒì¼ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "file_size": len(contents)
        })
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/ocr_upload")
async def ocr_upload(file: UploadFile = File(...)):
    """ì‚¬ì§„ ì—…ë¡œë“œ ë° OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬
        valid, error_msg = validate_file(file)
        if not valid:
            raise HTTPException(status_code=400, detail=error_msg)
        
        valid, error_msg = await validate_file_size(file)
        if not valid:
            raise HTTPException(status_code=400, detail=error_msg)
        
        contents = await file.read()
        
        # OCR ì²˜ë¦¬
        try:
            # Tesseract ì„¤ì¹˜ í™•ì¸
            if not TESSERACT_INSTALLED:
                return {
                    "success": False,
                    "ocr_text": "",
                    "message": "âŒ Tesseract OCRì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
                    "error": "Tesseract not installed"
                }
            
            # ì´ë¯¸ì§€ ì—´ê¸° ë° í˜•ì‹ í™•ì¸
            try:
                image = Image.open(io.BytesIO(contents))
                # ì´ë¯¸ì§€ í˜•ì‹ í™•ì¸ ë° RGBë¡œ ë³€í™˜
                if image.mode not in ('RGB', 'L'):
                    image = image.convert('RGB')
                    
            except Exception as img_error:
                return {
                    "success": False,
                    "ocr_text": "",
                    "message": f"âŒ ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì†ìƒë˜ì—ˆê±°ë‚˜ ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
                    "error": f"Image processing error: {str(img_error)}",
                    "suggestion": "JPG, PNG, BMP, GIF, TIFF, WebP í˜•ì‹ì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
                }
            
            # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆ
            if image.width > 2000 or image.height > 2000:
                image.thumbnail((2000, 2000), Image.Resampling.LANCZOS)
            
            # ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ í™•ëŒ€ (OCR ì„±ëŠ¥ í–¥ìƒ)
            elif image.width < 300 or image.height < 300:
                scale_factor = max(300 / image.width, 300 / image.height)
                new_size = (int(image.width * scale_factor), int(image.height * scale_factor))
                image = image.resize(new_size, Image.Resampling.LANCZOS)
            
            # ë‹¤ì¤‘ OCR ë°©ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
            try:
                ocr_results = try_multiple_ocr_methods(image)
                
                if ocr_results:
                    # í’ˆì§ˆ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ê²°ê³¼ë¥¼ ì„ íƒ
                    best_result = max(ocr_results, key=lambda x: x[2])  # quality_score ê¸°ì¤€
                    method_used = best_result[0]
                    text = best_result[1]
                    quality_score = best_result[2]
                    quality_desc = best_result[3]
                    
                    # í’ˆì§ˆì´ ë„ˆë¬´ ë‚®ìœ¼ë©´ ê²½ê³ 
                    if quality_score < 40:
                        warning_message = f"âš ï¸ í…ìŠ¤íŠ¸ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤ (í’ˆì§ˆ: {quality_desc}, {quality_score}ì ). ê²°ê³¼ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                    else:
                        warning_message = None
                    
                    # ë””ë²„ê¹… ì •ë³´ í¬í•¨ (í’ˆì§ˆ ì ìˆ˜ í¬í•¨)
                    debug_info = []
                    for method, result, q_score, q_desc in ocr_results:
                        short_result = result[:50] + "..." if len(result) > 50 else result
                        debug_info.append(f"{method} (í’ˆì§ˆ: {q_score}ì , {q_desc}): {short_result}")
                    
                    return {
                        "success": True,
                        "ocr_text": text,
                        "message": f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ! ({method_used} ë°©ë²• ì‚¬ìš©, í’ˆì§ˆ: {quality_desc})",
                        "quality_score": quality_score,
                        "quality_description": quality_desc,
                        "warning": warning_message,
                        "debug_info": debug_info,
                        "total_methods_tried": len(ocr_results),
                        "best_method": method_used
                    }
                else:
                    # ëª¨ë“  ë°©ë²•ì´ ì‹¤íŒ¨í•œ ê²½ìš°
                    return {
                        "success": True,
                        "ocr_text": "",
                        "message": "ğŸ“„ í…ìŠ¤íŠ¸ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "detailed_message": "6ê°€ì§€ ë‹¤ë¥¸ OCR ë°©ë²•ì„ ì‹œë„í–ˆì§€ë§Œ ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                        "suggestion": "ë‹¤ìŒì„ í™•ì¸í•´ë³´ì„¸ìš”:\nâ€¢ ê¸€ì”¨ê°€ ì„ ëª…í•˜ê³  ì½ì„ ìˆ˜ ìˆë‚˜ìš”?\nâ€¢ ë°°ê²½ê³¼ ê¸€ì”¨ì˜ ëŒ€ë¹„ê°€ ì¶©ë¶„í•œê°€ìš”?\nâ€¢ ì´ë¯¸ì§€ì— ë…¸ì´ì¦ˆë‚˜ ì–¼ë£©ì´ ë§ì§€ ì•Šë‚˜ìš”?\nâ€¢ ê¸€ì”¨ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ì§€ ì•Šë‚˜ìš”?\nâ€¢ ì†ê¸€ì”¨ê°€ ë„ˆë¬´ í˜ë¦¼ì²´ëŠ” ì•„ë‹Œê°€ìš”?",
                        "quality_info": "ëª¨ë“  OCR ë°©ë²•ì—ì„œ ê¹¨ì§„ ê¸€ìë‚˜ ì˜ë¯¸ì—†ëŠ” ë¬¸ìë§Œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤."
                    }
                    
            except Exception as ocr_error:
                return {
                    "success": False,
                    "ocr_text": "",
                    "message": "âŒ OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "error": f"OCR error: {str(ocr_error)}",
                    "suggestion": "ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”."
                }
            
        except Exception as ocr_error:
            raise HTTPException(
                status_code=500, 
                detail=f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì‚¬ì§„ì„ ì‹œë„í•´ë³´ì„¸ìš”. (ìƒì„¸: {str(ocr_error)})"
            )
    
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/ai_feedback")
async def ai_feedback(text: str = Body(..., embed=True)):
    """AI í”¼ë“œë°± ìƒì„±"""
    try:
        if not text or not text.strip():
            raise HTTPException(status_code=400, detail="ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if len(text.strip()) < 10:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 10ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise HTTPException(
                status_code=500, 
                detail="AI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            )
        
        openai.api_key = api_key
        prompt = f"""
        ì•„ë˜ëŠ” í•™ìƒì´ ì“´ ê¸€ì…ë‹ˆë‹¤. ì´ ê¸€ì„ ì½ê³  í•™ìƒì˜ ìƒê°ì„ í™•ì¥ì‹œì¼œì¤„ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ ë˜ëŠ” ì½”ì¹­ì„ 2ê°œ ìƒì„±í•´ ì£¼ì„¸ìš”. 
        í•™ìƒì´ ì´í•´í•˜ê¸° ì‰½ê³  ê±´ì„¤ì ì¸ í”¼ë“œë°±ì„ ì œê³µí•´ì£¼ì„¸ìš”. ê° í•­ëª©ì€ ë²ˆí˜¸ë¡œ êµ¬ë¶„í•´ ì£¼ì„¸ìš”.
        
        ---
        {text}
        ---
        
        ì§ˆë¬¸/ì½”ì¹­:
        """
        
        try:
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.7
            )
            feedback = response.choices[0].message.content.strip()
            
            if not feedback:
                raise HTTPException(status_code=500, detail="AI í”¼ë“œë°±ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
            return {
                "feedback": feedback,
                "message": "AI í”¼ë“œë°±ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "input_length": len(text)
            }
            
        except openai.RateLimitError:
            raise HTTPException(status_code=429, detail="AI ì„œë¹„ìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        except openai.APIError as api_error:
            raise HTTPException(status_code=500, detail=f"AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(api_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI í”¼ë“œë°± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def extract_stage_from_evaluation(evaluation: str) -> int:
    """AI í‰ê°€ì—ì„œ ë‹¨ê³„ ì¶”ì¶œ"""
    match = re.search(r'ë‹¨ê³„:\s*([123])', evaluation)
    if match:
        return int(match.group(1))
    return 2  # ê¸°ë³¸ê°’

@app.post("/ai_evaluate")
async def ai_evaluate(
    text: str = Body(...), 
    submission_id: int = Body(...)
):
    """AI ìµœì¢… í‰ê°€"""
    try:
        if not text or not text.strip():
            raise HTTPException(status_code=400, detail="í‰ê°€í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        if len(text.strip()) < 10:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìµœì†Œ 10ì ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise HTTPException(
                status_code=500, 
                detail="AI ì„œë¹„ìŠ¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            )
        
        openai.api_key = api_key
        prompt = f"""
        ì•„ë˜ëŠ” í•™ìƒì´ ì“´ ê¸€ì…ë‹ˆë‹¤. ì´ ê¸€ì„ ë£¨ë¸Œë¦­ ê¸°ì¤€ì— ë”°ë¼ ì•„ë˜ ë‹¨ê³„ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³ , ê·¸ ì´ìœ ì™€ ê°œì„  ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        
        [ë‹¨ê³„]
        1ë‹¨ê³„: ì£¼ì œì™€ ê´€ë ¨ ì—†ëŠ” ê¸€
        2ë‹¨ê³„: ì£¼ì œì™€ ê´€ë ¨ ìˆìœ¼ë‚˜ ë‚´ìš©ì´ ë¶€ì¡±í•¨
        3ë‹¨ê³„: ì£¼ì œì— ë§ëŠ” ë‚´ìš©ê³¼ ê·¼ê±°ê°€ ì¶©ë¶„í•¨
        
        ---
        {text}
        ---
        
        [ì¶œë ¥ ì˜ˆì‹œ]
        ë‹¨ê³„: (1/2/3 ì¤‘ í•˜ë‚˜)
        ì½”ë©˜íŠ¸: (ê°„ë‹¨í•œ í‰ê°€ ë° ê°œì„ ì )
        """
        
        try:
            response = openai.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=300,
                temperature=0.7
            )
            result = response.choices[0].message.content.strip()
            
            if not result:
                raise HTTPException(status_code=500, detail="AI í‰ê°€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            
            stage = extract_stage_from_evaluation(result)
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— AI í‰ê°€ ê²°ê³¼ ì €ì¥
            if db:
                db.update_ai_evaluation(submission_id, result, stage)
            
            return {
                "evaluation": result,
                "stage": stage,
                "message": "AI í‰ê°€ê°€ ì™„ë£Œë˜ê³  ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "input_length": len(text),
                "submission_id": submission_id
            }
            
        except openai.RateLimitError:
            raise HTTPException(status_code=429, detail="AI ì„œë¹„ìŠ¤ ì‚¬ìš©ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        except openai.APIError as api_error:
            raise HTTPException(status_code=500, detail=f"AI ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(api_error)}")
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AI í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/submit_revision")
async def submit_revision(
    student_id: str = Body(...), 
    original_text: str = Body(...), 
    revised_text: str = Body(...)
):
    """í•™ìƒì´ ìˆ˜ì •í•œ ê¸€ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    try:
        if not db:
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if not student_id or not student_id.strip():
            raise HTTPException(status_code=400, detail="í•™ìƒ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        if not revised_text or not revised_text.strip():
            raise HTTPException(status_code=400, detail="ìˆ˜ì •ëœ ê¸€ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        submission_id = db.save_submission(student_id.strip(), original_text, revised_text.strip())
        
        return JSONResponse(content={
            "message": "ê¸€ ì œì¶œì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "submission_id": submission_id,
            "submit_time": datetime.now().isoformat(),
            "student_id": student_id.strip()
        })
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì œì¶œ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/submit_full_evaluation")
async def submit_full_evaluation(
    student_id: str = Body(...), 
    original_text: str = Body(...), 
    revised_text: str = Body(...),
    ai_feedback: str = Body(...),
    ai_evaluation: str = Body(...)
):
    """ì „ì²´ í‰ê°€ í”„ë¡œì„¸ìŠ¤ í•œë²ˆì— ì €ì¥"""
    try:
        if not db:
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        submission_id = db.save_submission(student_id, original_text, revised_text)
        db.update_ai_feedback(submission_id, ai_feedback)
        
        # AI í‰ê°€ì—ì„œ ë‹¨ê³„ ì¶”ì¶œ
        stage = extract_stage_from_evaluation(ai_evaluation)
        db.update_ai_evaluation(submission_id, ai_evaluation, stage)
        
        return JSONResponse(content={
            "message": "ì „ì²´ í‰ê°€ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "submission_id": submission_id,
            "stage": stage,
            "submit_time": datetime.now().isoformat()
        })
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"í‰ê°€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

# êµì‚¬ìš© API
@app.get("/teacher/submissions")
async def get_all_submissions():
    """ëª¨ë“  í•™ìƒ ì œì¶œ ë‚´ì—­ ì¡°íšŒ (êµì‚¬ìš©)"""
    try:
        if not db:
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        submissions = db.get_all_submissions()
        return {
            "submissions": submissions,
            "total_count": len(submissions),
            "message": "ì œì¶œ ë‚´ì—­ì„ ì„±ê³µì ìœ¼ë¡œ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤."
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/teacher/student/{student_id}")
async def get_student_submissions(student_id: str):
    """íŠ¹ì • í•™ìƒì˜ ëª¨ë“  ì œì¶œ ë‚´ì—­ ì¡°íšŒ"""
    try:
        if not db:
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        if not student_id or not student_id.strip():
            raise HTTPException(status_code=400, detail="í•™ìƒ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        submissions = db.get_student_submissions(student_id.strip())
        return {
            "student_id": student_id.strip(),
            "submissions": submissions,
            "total_count": len(submissions),
            "message": f"{student_id} í•™ìƒì˜ ì œì¶œ ë‚´ì—­ì„ ì¡°íšŒí–ˆìŠµë‹ˆë‹¤."
        }
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/submission/{submission_id}")
async def get_submission(submission_id: int):
    """íŠ¹ì • ì œì¶œ ë‚´ì—­ ìƒì„¸ ì¡°íšŒ"""
    try:
        if not db:
            raise HTTPException(status_code=500, detail="ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        submission = db.get_submission_by_id(submission_id)
        if not submission:
            raise HTTPException(status_code=404, detail="ì œì¶œ ë‚´ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return submission
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/health")
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "status": "healthy",
        "message": "AI í•™ìƒ ê¸€ í‰ê°€ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "version": "2.0",
        "database": "connected" if db else "disconnected",
        "timestamp": datetime.now().isoformat()
    }

@app.get("/")
def read_root():
    return {
        "message": "ğŸ“ AI í•™ìƒ ê¸€ í‰ê°€ ì‹œìŠ¤í…œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!",
        "version": "2.0 with Database",
        "endpoints": {
            "í•™ìƒìš©": "/ocr_upload, /ai_feedback, /ai_evaluate, /submit_revision",
            "êµì‚¬ìš©": "/teacher/submissions, /teacher/student/{student_id}",
            "ê¸°íƒ€": "/health, /docs"
        },
        "frontend": {
            "í•™ìƒìš©": "student.html",
            "êµì‚¬ìš©": "teacher.html",
            "í…ŒìŠ¤íŠ¸ìš©": "test.html"
        }
    } 

def korean_language_correction(text):
    """í•œêµ­ì–´ ì–¸ì–´ëª¨ë¸ ê¸°ë°˜ í…ìŠ¤íŠ¸ êµì •"""
    if not text:
        return text
    
    print(f"ğŸ”¤ ì–¸ì–´ëª¨ë¸ êµì • ì‹œì‘: '{text}'")
    
    # 1. ìì£¼ ì˜ëª» ì¸ì‹ë˜ëŠ” ê¸€ì êµì •
    common_mistakes = {
        # ìœ ì‚¬í•œ ëª¨ì–‘ì˜ ê¸€ìë“¤
        'ë°‘': 'ë²•',  # 'ã…'ê³¼ 'ã…‚' í˜¼ë™
        'ê°€': 'ë‚˜',  # 'ã„±'ê³¼ 'ã„´' í˜¼ë™
        'ì •': 'ì •',  # ê·¸ëŒ€ë¡œ
        'í•´': 'í•´',  # ê·¸ëŒ€ë¡œ
        'ê±¸': 'ê±¸',  # ê·¸ëŒ€ë¡œ
        'ê¼­': 'ê¼­',  # ê·¸ëŒ€ë¡œ
        'ì§€': 'ì§€',  # ê·¸ëŒ€ë¡œ
        'ì¼œ': 'ì¼œ',  # ê·¸ëŒ€ë¡œ
        'ì•¼': 'ì•¼',  # ê·¸ëŒ€ë¡œ
        'í•˜': 'í•˜',  # ê·¸ëŒ€ë¡œ
        'ëŠ”': 'ëŠ”',  # ê·¸ëŒ€ë¡œ
        'ê²ƒ': 'ê²ƒ',  # ê·¸ëŒ€ë¡œ
        'ê°•': 'ê°•',  # ê·¸ëŒ€ë¡œ
        'ì œ': 'ì œ',  # ê·¸ëŒ€ë¡œ
        'ì ': 'ì ',  # ê·¸ëŒ€ë¡œ
        'ìœ¼': 'ìœ¼',  # ê·¸ëŒ€ë¡œ
        'ë¡œ': 'ë¡œ',  # ê·¸ëŒ€ë¡œ
        'ì²´': 'ì²´',  # ê·¸ëŒ€ë¡œ
        'ë²Œ': 'ë²Œ',  # ê·¸ëŒ€ë¡œ
        'ì„': 'ì„',  # ê·¸ëŒ€ë¡œ
        'ë°›': 'ë°›',  # ê·¸ëŒ€ë¡œ
        'ê³ ': 'ê³ ',  # ê·¸ëŒ€ë¡œ
        'ë„': 'ë„',  # ê·¸ëŒ€ë¡œ
        'ë•': 'ë•',  # ê·¸ëŒ€ë¡œ
        'ì€': 'ì€',  # ê·¸ëŒ€ë¡œ
        'ì–‘': 'ì–‘',  # ê·¸ëŒ€ë¡œ
        'ì‹¬': 'ì‹¬',  # ê·¸ëŒ€ë¡œ
        'ì˜': 'ì˜',  # ê·¸ëŒ€ë¡œ
        'ì‹¤': 'ì‹¤',  # ê·¸ëŒ€ë¡œ
        'ë§': 'ë§',  # ê·¸ëŒ€ë¡œ
        'ê³¼': 'ê³¼',  # ê·¸ëŒ€ë¡œ
        'ë¹„': 'ë¹„',  # ê·¸ëŒ€ë¡œ
        'ë‚œ': 'ë‚œ',  # ê·¸ëŒ€ë¡œ
        'ë‹¤': 'ë‹¤',  # ê·¸ëŒ€ë¡œ
        
        # ìì£¼ ì˜ëª» ì¸ì‹ë˜ëŠ” íŒ¨í„´ë“¤
        'ì²´ë‹ˆ': 'ì²´ë²Œ',
        'ì„±ì•™': 'ì‹¤ë§',
        'ë²„ì–¸': 'ë°›ëŠ”',
        'ì˜¤ê³ ': 'ì„',
        'ì–µ': 'ë„ë•',
        'ì•™ê°€': 'ê³¼',
    }
    
    corrected = text
    corrections_made = []
    
    for wrong, correct in common_mistakes.items():
        if wrong in corrected:
            corrected = corrected.replace(wrong, correct)
            corrections_made.append(f"{wrong}â†’{correct}")
    
    if corrections_made:
        print(f"  ğŸ“ ê¸€ì êµì •: {', '.join(corrections_made)}")
    
    # 2. ë‹¨ì–´ ê²½ê³„ ì¶”ë¡  ë° êµì •
    word_patterns = [
        # ë²•ë¥  ê´€ë ¨ ìš©ì–´
        (r'ë²•.*?ëŠ”', 'ë²•ì€'),
        (r'ë‚˜.*?ë¼.*?ì—.*?ì„œ', 'ë‚˜ë¼ì—ì„œ'),
        (r'ì •.*?í•´.*?ì¤€.*?ê±¸', 'ì •í•´ì¤€ ê±¸'),
        (r'ê¼­.*?ì§€.*?ì¼œ.*?ì•¼', 'ê¼­ ì§€ì¼œì•¼'),
        (r'í•˜.*?ëŠ”.*?ê²ƒ', 'í•˜ëŠ” ê²ƒ'),
        (r'ê°•.*?ì œ.*?ì .*?ìœ¼.*?ë¡œ', 'ê°•ì œì ìœ¼ë¡œ'),
        (r'ì²´.*?ë²Œ.*?ì„', 'ì²´ë²Œì„'),
        (r'ë°›.*?ê³ ', 'ë°›ê³ '),
        (r'ë„.*?ë•.*?ì€', 'ë„ë•ì€'),
        (r'ì–‘.*?ì‹¬.*?ì˜', 'ì–‘ì‹¬ì˜'),
        (r'ì‹¤.*?ë§.*?ê³¼', 'ì‹¤ë§ê³¼'),
        (r'ë¹„.*?ë‚œ.*?ì„', 'ë¹„ë‚œì„'),
        (r'ë°›.*?ëŠ”.*?ë‹¤', 'ë°›ëŠ”ë‹¤'),
    ]
    
    for pattern, replacement in word_patterns:
        if re.search(pattern, corrected):
            old_text = corrected
            corrected = re.sub(pattern, replacement, corrected)
            if old_text != corrected:
                print(f"  ğŸ” íŒ¨í„´ êµì •: '{old_text}' â†’ '{corrected}'")
    
    # 3. ë¬¸ì¥ êµ¬ì¡° ë³µì›
    # ì‰¼í‘œì™€ ë§ˆì¹¨í‘œ ì¶”ê°€
    if 'ê²ƒ' in corrected and 'ë²•ì€' in corrected and ',' not in corrected:
        corrected = corrected.replace('ê²ƒ', 'ê²ƒ,')
        print(f"  ğŸ“– ë¬¸ì¥ë¶€í˜¸ ì¶”ê°€: ì‰¼í‘œ ì‚½ì…")
    
    if corrected and not corrected.endswith('.'):
        if any(ending in corrected for ending in ['ë‹¤', 'ìš”', 'ìŒ', 'ë‹ˆë‹¤']):
            corrected += '.'
            print(f"  ğŸ“– ë¬¸ì¥ë¶€í˜¸ ì¶”ê°€: ë§ˆì¹¨í‘œ ì‚½ì…")
    
    # 4. ìµœì¢… ì •ë¦¬
    corrected = re.sub(r'\s+', ' ', corrected)  # ì—°ì† ê³µë°± ì œê±°
    corrected = corrected.strip()
    
    if corrected != text:
        print(f"âœ… êµì • ì™„ë£Œ: '{text}' â†’ '{corrected}'")
        return corrected
    else:
        print(f"â„¹ï¸ êµì • ë¶ˆí•„ìš”: '{text}'")
        return text

def enhance_korean_ocr_result(text):
    """í•œêµ­ì–´ OCR ê²°ê³¼ ì¢…í•© ê°œì„ """
    if not text:
        return text
    
    print(f"ğŸš€ í•œêµ­ì–´ OCR ê²°ê³¼ ì¢…í•© ê°œì„  ì‹œì‘")
    
    # 1. ê¸°ë³¸ ì •ë¦¬
    cleaned = clean_korean_ocr_text(text)
    if not cleaned:
        print(f"âŒ ê¸°ë³¸ ì •ë¦¬ ë‹¨ê³„ì—ì„œ ì œê±°ë¨")
        return ""
    
    # 2. ì–¸ì–´ëª¨ë¸ êµì •
    corrected = korean_language_correction(cleaned)
    
    # 3. ìµœì¢… í’ˆì§ˆ í‰ê°€
    final_score, final_desc, final_analysis = analyze_korean_text_quality(corrected)
    
    print(f"ğŸ“Š ìµœì¢… í’ˆì§ˆ: {final_score}ì  ({final_desc})")
    print(f"ğŸ¯ ìµœì¢… ê²°ê³¼: '{corrected}'")
    
    return corrected 